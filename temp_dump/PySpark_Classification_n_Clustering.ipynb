{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages net.snowflake:snowflake-jdbc:3.6.24,net.snowflake:spark-snowflake_2.11:2.4.12-spark_2.3 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkConf, SparkContext \n",
    "\n",
    "#ML\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.classification import GBTClassifier, DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer, VectorAssembler, IndexToString\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession.Builder at 0x11164f9b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master('local').appName('playground').config('spark.driver.memory', '5G').getOrCreate()\n",
    "spark.builder.config('spark.executor.memory', '16G')\n",
    "spark.builder.config(\"spark.executor.cores\", \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNOWFLAKE_SOURCE_NAME = \"net.snowflake.spark.snowflake\"\n",
    "sfOptions = {\"sfURL\":\"*\", \"sfAccount\":\"*\", \"sfUser\":\"*\", \"sfPassword\":\"*\", \"sfDatabase\":\"*\", \"sfSchema\":\"*\", \"sfWarehouse\":\"*\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+-----------+----------+-------+\n",
      "| Id|SepalLength|SepalWidth|PetalLength|PetalWidth|Species|\n",
      "+---+-----------+----------+-----------+----------+-------+\n",
      "|  1|        5.1|       3.5|        1.4|       0.2| setosa|\n",
      "|  2|        4.9|       3.0|        1.4|       0.2| setosa|\n",
      "|  3|        4.7|       3.2|        1.3|       0.2| setosa|\n",
      "|  4|        4.6|       3.1|        1.5|       0.2| setosa|\n",
      "|  5|        5.0|       3.6|        1.4|       0.2| setosa|\n",
      "+---+-----------+----------+-----------+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Importing Data \n",
    "df = spark.read.csv('/Users/spurushe/Downloads/iris.csv', header='true', inferSchema='true')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#StringIndexer () is an Estimator which returns a Transformer (labelIndexer)\n",
    "# Converts label String classes to indices --- for e.g. 'good', 'bad', 'ugly' to 0,1,2\n",
    "labelIndexer = StringIndexer(inputCol=\"Species\", outputCol=\"indexedLabel\").fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureAssembler = VectorAssembler(inputCols= [x for x in df.columns if x != 'Species' and x != 'Id'], outputCol=\"features\")\n",
    "\n",
    "featureIndexer =VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+-----------+----------+-------+-----------------+-----------------+\n",
      "| Id|SepalLength|SepalWidth|PetalLength|PetalWidth|Species|         features|  indexedFeatures|\n",
      "+---+-----------+----------+-----------+----------+-------+-----------------+-----------------+\n",
      "|  1|        5.1|       3.5|        1.4|       0.2| setosa|[5.1,3.5,1.4,0.2]|[5.1,3.5,1.4,0.2]|\n",
      "|  2|        4.9|       3.0|        1.4|       0.2| setosa|[4.9,3.0,1.4,0.2]|[4.9,3.0,1.4,0.2]|\n",
      "|  3|        4.7|       3.2|        1.3|       0.2| setosa|[4.7,3.2,1.3,0.2]|[4.7,3.2,1.3,0.2]|\n",
      "|  4|        4.6|       3.1|        1.5|       0.2| setosa|[4.6,3.1,1.5,0.2]|[4.6,3.1,1.5,0.2]|\n",
      "|  5|        5.0|       3.6|        1.4|       0.2| setosa|[5.0,3.6,1.4,0.2]|[5.0,3.6,1.4,0.2]|\n",
      "|  6|        5.4|       3.9|        1.7|       0.4| setosa|[5.4,3.9,1.7,0.4]|[5.4,3.9,1.7,0.4]|\n",
      "|  7|        4.6|       3.4|        1.4|       0.3| setosa|[4.6,3.4,1.4,0.3]|[4.6,3.4,1.4,0.3]|\n",
      "|  8|        5.0|       3.4|        1.5|       0.2| setosa|[5.0,3.4,1.5,0.2]|[5.0,3.4,1.5,0.2]|\n",
      "|  9|        4.4|       2.9|        1.4|       0.2| setosa|[4.4,2.9,1.4,0.2]|[4.4,2.9,1.4,0.2]|\n",
      "| 10|        4.9|       3.1|        1.5|       0.1| setosa|[4.9,3.1,1.5,0.1]|[4.9,3.1,1.5,0.1]|\n",
      "| 11|        5.4|       3.7|        1.5|       0.2| setosa|[5.4,3.7,1.5,0.2]|[5.4,3.7,1.5,0.2]|\n",
      "| 12|        4.8|       3.4|        1.6|       0.2| setosa|[4.8,3.4,1.6,0.2]|[4.8,3.4,1.6,0.2]|\n",
      "| 13|        4.8|       3.0|        1.4|       0.1| setosa|[4.8,3.0,1.4,0.1]|[4.8,3.0,1.4,0.1]|\n",
      "| 14|        4.3|       3.0|        1.1|       0.1| setosa|[4.3,3.0,1.1,0.1]|[4.3,3.0,1.1,0.1]|\n",
      "| 15|        5.8|       4.0|        1.2|       0.2| setosa|[5.8,4.0,1.2,0.2]|[5.8,4.0,1.2,0.2]|\n",
      "| 16|        5.7|       4.4|        1.5|       0.4| setosa|[5.7,4.4,1.5,0.4]|[5.7,4.4,1.5,0.4]|\n",
      "| 17|        5.4|       3.9|        1.3|       0.4| setosa|[5.4,3.9,1.3,0.4]|[5.4,3.9,1.3,0.4]|\n",
      "| 18|        5.1|       3.5|        1.4|       0.3| setosa|[5.1,3.5,1.4,0.3]|[5.1,3.5,1.4,0.3]|\n",
      "| 19|        5.7|       3.8|        1.7|       0.3| setosa|[5.7,3.8,1.7,0.3]|[5.7,3.8,1.7,0.3]|\n",
      "| 20|        5.1|       3.8|        1.5|       0.3| setosa|[5.1,3.8,1.5,0.3]|[5.1,3.8,1.5,0.3]|\n",
      "+---+-----------+----------+-----------+----------+-------+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fa = featureAssembler.transform(df)\n",
    "featureIndexer.fit(fa).transform(fa).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexers and Decision tree in a Pipeline\n",
    "trans_pipeline = Pipeline(stages=[labelIndexer, featureAssembler, featureIndexer])\n",
    "transformed_df = trans_pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*******************************************\n",
    "# SINGLE TRAIN TEST SPLIT\n",
    "#*******************************************.\n",
    "(trainingData, testData) = transformed_df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*******************************************\n",
    "# TRAINING THE MODEL\n",
    "#*******************************************.\n",
    "dec_t = DecisionTreeClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "# Estimators' .fit() returns a Transformer (model)\n",
    "model = dec_t.fit(trainingData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*******************************************\n",
    "# PREDICTION\n",
    "#*******************************************\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+----------+-------------+\n",
      "| Id|indexedLabel|prediction|  probability|\n",
      "+---+------------+----------+-------------+\n",
      "|  1|         2.0|       2.0|[0.0,0.0,1.0]|\n",
      "|  6|         2.0|       2.0|[0.0,0.0,1.0]|\n",
      "|  9|         2.0|       2.0|[0.0,0.0,1.0]|\n",
      "| 10|         2.0|       2.0|[0.0,0.0,1.0]|\n",
      "| 11|         2.0|       2.0|[0.0,0.0,1.0]|\n",
      "+---+------------+----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Quick view at columns of interest\n",
    "predictions.select('Id', 'indexedLabel', 'prediction', 'probability').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- SepalLength: double (nullable = true)\n",
      " |-- SepalWidth: double (nullable = true)\n",
      " |-- PetalLength: double (nullable = true)\n",
      " |-- PetalWidth: double (nullable = true)\n",
      " |-- Species: string (nullable = true)\n",
      " |-- indexedLabel: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      " |-- indexedFeatures: vector (nullable = true)\n",
      " |-- rawPrediction: vector (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Species='setosa', indexedLabel=2.0, Predicted_label='setosa'),\n",
       " Row(Species='setosa', indexedLabel=2.0, Predicted_label='setosa'),\n",
       " Row(Species='setosa', indexedLabel=2.0, Predicted_label='setosa'),\n",
       " Row(Species='setosa', indexedLabel=2.0, Predicted_label='setosa'),\n",
       " Row(Species='setosa', indexedLabel=2.0, Predicted_label='setosa'),\n",
       " Row(Species='setosa', indexedLabel=2.0, Predicted_label='setosa'),\n",
       " Row(Species='setosa', indexedLabel=2.0, Predicted_label='setosa'),\n",
       " Row(Species='setosa', indexedLabel=2.0, Predicted_label='setosa'),\n",
       " Row(Species='setosa', indexedLabel=2.0, Predicted_label='setosa'),\n",
       " Row(Species='setosa', indexedLabel=2.0, Predicted_label='setosa'),\n",
       " Row(Species='versicolor', indexedLabel=0.0, Predicted_label='versicolor'),\n",
       " Row(Species='versicolor', indexedLabel=0.0, Predicted_label='versicolor'),\n",
       " Row(Species='versicolor', indexedLabel=0.0, Predicted_label='versicolor'),\n",
       " Row(Species='versicolor', indexedLabel=0.0, Predicted_label='versicolor'),\n",
       " Row(Species='versicolor', indexedLabel=0.0, Predicted_label='versicolor'),\n",
       " Row(Species='versicolor', indexedLabel=0.0, Predicted_label='versicolor'),\n",
       " Row(Species='versicolor', indexedLabel=0.0, Predicted_label='versicolor'),\n",
       " Row(Species='versicolor', indexedLabel=0.0, Predicted_label='versicolor'),\n",
       " Row(Species='versicolor', indexedLabel=0.0, Predicted_label='versicolor'),\n",
       " Row(Species='versicolor', indexedLabel=0.0, Predicted_label='versicolor'),\n",
       " Row(Species='virginica', indexedLabel=1.0, Predicted_label='virginica'),\n",
       " Row(Species='virginica', indexedLabel=1.0, Predicted_label='virginica'),\n",
       " Row(Species='virginica', indexedLabel=1.0, Predicted_label='virginica'),\n",
       " Row(Species='virginica', indexedLabel=1.0, Predicted_label='virginica'),\n",
       " Row(Species='virginica', indexedLabel=1.0, Predicted_label='virginica'),\n",
       " Row(Species='virginica', indexedLabel=1.0, Predicted_label='virginica'),\n",
       " Row(Species='virginica', indexedLabel=1.0, Predicted_label='virginica'),\n",
       " Row(Species='virginica', indexedLabel=1.0, Predicted_label='virginica'),\n",
       " Row(Species='virginica', indexedLabel=1.0, Predicted_label='virginica'),\n",
       " Row(Species='virginica', indexedLabel=1.0, Predicted_label='virginica')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert indices back to labels\n",
    "in_to_label = IndexToString(inputCol='indexedLabel', outputCol='Predicted_label').transform(predictions)\n",
    "in_to_label.select('Species','indexedLabel', 'Predicted_label').head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our DT model in predicting flowers is  0.9787234042553191\n"
     ]
    }
   ],
   "source": [
    "#*******************************************\n",
    "# EVALUATION\n",
    "#\n",
    "# evaluating the performance of our ML model\n",
    "#*******************************************\n",
    "\n",
    "eva = MulticlassClassificationEvaluator(labelCol='indexedLabel', predictionCol='prediction', metricName='accuracy')\n",
    "\n",
    "accuracy = eva.evaluate(predictions)\n",
    "print(\"Accuracy of our DT model in predicting flowers is \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_4b47940cb17f3c92f771) of depth 5 with 17 nodes\n",
      "  If (feature 2 <= 2.35)\n",
      "   Predict: 2.0\n",
      "  Else (feature 2 > 2.35)\n",
      "   If (feature 3 <= 1.75)\n",
      "    If (feature 2 <= 5.05)\n",
      "     If (feature 0 <= 4.95)\n",
      "      If (feature 1 <= 2.45)\n",
      "       Predict: 0.0\n",
      "      Else (feature 1 > 2.45)\n",
      "       Predict: 1.0\n",
      "     Else (feature 0 > 4.95)\n",
      "      Predict: 0.0\n",
      "    Else (feature 2 > 5.05)\n",
      "     If (feature 0 <= 6.05)\n",
      "      Predict: 0.0\n",
      "     Else (feature 0 > 6.05)\n",
      "      Predict: 1.0\n",
      "   Else (feature 3 > 1.75)\n",
      "    If (feature 2 <= 4.85)\n",
      "     If (feature 0 <= 5.95)\n",
      "      Predict: 0.0\n",
      "     Else (feature 0 > 5.95)\n",
      "      Predict: 1.0\n",
      "    Else (feature 2 > 4.85)\n",
      "     Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Getting the entire Decision Tree rules.\n",
    "\n",
    "print(model.toDebugString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the probability column into the respective number of columns \n",
    "(One column per category of the target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = predictions.select('Id', 'indexedLabel', 'prediction', 'probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+----------+-------------+\n",
      "| Id|indexedLabel|prediction|  probability|\n",
      "+---+------------+----------+-------------+\n",
      "|  1|         2.0|       2.0|[0.0,0.0,1.0]|\n",
      "|  6|         2.0|       2.0|[0.0,0.0,1.0]|\n",
      "|  9|         2.0|       2.0|[0.0,0.0,1.0]|\n",
      "| 10|         2.0|       2.0|[0.0,0.0,1.0]|\n",
      "| 11|         2.0|       2.0|[0.0,0.0,1.0]|\n",
      "+---+------------+----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subset.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- indexedLabel: double (nullable = false)\n",
      " |-- prediction: double (nullable = false)\n",
      " |-- probability: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "subset.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using a udf here (permisson problems with rdd solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "\n",
    "def to_array(col):\n",
    "    def to_array_(v):\n",
    "        return v.toArray().tolist()\n",
    "    return udf(to_array_, ArrayType(DoubleType()))(col)\n",
    "\n",
    "d = predictions\\\n",
    "    .withColumn(\"xs\", to_array(col(\"probability\")))\\\n",
    "    .select(['Id','probability', 'prediction'] + [col(\"xs\")[i] for i in range(3)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id', 'probability', 'prediction', 'xs[0]', 'xs[1]', 'xs[2]']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(k = 3, seed=2018, featuresCol=\"probability\", predictionCol='clustered_prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_df = kmeans.fit(d).transform(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id',\n",
       " 'probability',\n",
       " 'prediction',\n",
       " 'xs[0]',\n",
       " 'xs[1]',\n",
       " 'xs[2]',\n",
       " 'clustered_prediction']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- probability: vector (nullable = true)\n",
      " |-- prediction: double (nullable = false)\n",
      " |-- xs[0]: double (nullable = true)\n",
      " |-- xs[1]: double (nullable = true)\n",
      " |-- xs[2]: double (nullable = true)\n",
      " |-- clustered_prediction: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clustered_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id', 'prediction', 'xs[0]', 'xs[1]', 'xs[2]', 'clustered_prediction']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selections = [x[0] for x in clustered_df.dtypes if x[1] != 'vector']\n",
    "selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id',\n",
       " 'probability',\n",
       " 'prediction',\n",
       " 'xs[0]',\n",
       " 'xs[1]',\n",
       " 'xs[2]',\n",
       " 'clustered_prediction']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clustered_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------+-----+-----+-----+--------------------+\n",
      "| Id|  probability|prediction|xs[0]|xs[1]|xs[2]|clustered_prediction|\n",
      "+---+-------------+----------+-----+-----+-----+--------------------+\n",
      "|  1|[0.0,0.0,1.0]|       2.0|  0.0|  0.0|  1.0|                   0|\n",
      "|  6|[0.0,0.0,1.0]|       2.0|  0.0|  0.0|  1.0|                   0|\n",
      "|  9|[0.0,0.0,1.0]|       2.0|  0.0|  0.0|  1.0|                   0|\n",
      "| 10|[0.0,0.0,1.0]|       2.0|  0.0|  0.0|  1.0|                   0|\n",
      "| 11|[0.0,0.0,1.0]|       2.0|  0.0|  0.0|  1.0|                   0|\n",
      "+---+-------------+----------+-----+-----+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clustered_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustered_df.select(selections)\\\n",
    "        .write.format(SNOWFLAKE_SOURCE_NAME)\\\n",
    "        .mode(\"overwrite\")\\\n",
    "        .options(**sfOptions)\\\n",
    "        .option(\"dbtable\", \"dev.zsp.iris_clustered\")\\\n",
    "        .save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
