{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal \n",
    "Complete Pipeline for handling ML **preprocessing** for categorical *and* continuous data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as pyf\n",
    "from pyspark.sql.types import *\n",
    "import functools\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import RobustScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"local[4]\") \\\n",
    "        .appName(\"churn_pred\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://10.0.0.179:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0-preview2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>churn_pred</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x115061550>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = spark.createDataFrame([(0,22,1, 11), (1,5,77, 12), (10,2,3, 21)]\n",
    "                              , [\"x\", \"y\", \"z\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_x_y = VectorAssembler(inputCols=[\"x\", \"y\"], outputCol='x_y_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o1 = va_x_y.transform(my_df)\n",
    "o1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_z_a = VectorAssembler(inputCols=[\"z\", \"a\"], outputCol=\"z_a_features\")\n",
    "o2 = va_z_a.transform(o1)\n",
    "o2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "va_final = VectorAssembler(inputCols=[\"x_y_features\", \"z_a_features\"], outputCol=\"final\")\n",
    "final_df = va_final.transform(o2)\n",
    "final_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "### Now with a real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_df = spark.read.format(\"csv\").load('/Users/spurushe/Documents/data-science-world/input_data/iris.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+-----------+----------+-------+\n",
      "| Id|SepalLength|SepalWidth|PetalLength|PetalWidth|Species|\n",
      "+---+-----------+----------+-----------+----------+-------+\n",
      "|  1|        5.1|       3.5|        1.4|       0.2| setosa|\n",
      "|  2|        4.9|       3.0|        1.4|       0.2| setosa|\n",
      "|  3|        4.7|       3.2|        1.3|       0.2| setosa|\n",
      "|  4|        4.6|       3.1|        1.5|       0.2| setosa|\n",
      "|  5|        5.0|       3.6|        1.4|       0.2| setosa|\n",
      "+---+-----------+----------+-----------+----------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_va = VectorAssembler(inputCols=['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth'], outputCol='num_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+-----------+----------+-------+-----------------+\n",
      "| Id|SepalLength|SepalWidth|PetalLength|PetalWidth|Species|     num_features|\n",
      "+---+-----------+----------+-----------+----------+-------+-----------------+\n",
      "|  1|        5.1|       3.5|        1.4|       0.2| setosa|[5.1,3.5,1.4,0.2]|\n",
      "|  2|        4.9|       3.0|        1.4|       0.2| setosa|[4.9,3.0,1.4,0.2]|\n",
      "|  3|        4.7|       3.2|        1.3|       0.2| setosa|[4.7,3.2,1.3,0.2]|\n",
      "|  4|        4.6|       3.1|        1.5|       0.2| setosa|[4.6,3.1,1.5,0.2]|\n",
      "|  5|        5.0|       3.6|        1.4|       0.2| setosa|[5.0,3.6,1.4,0.2]|\n",
      "|  6|        5.4|       3.9|        1.7|       0.4| setosa|[5.4,3.9,1.7,0.4]|\n",
      "|  7|        4.6|       3.4|        1.4|       0.3| setosa|[4.6,3.4,1.4,0.3]|\n",
      "|  8|        5.0|       3.4|        1.5|       0.2| setosa|[5.0,3.4,1.5,0.2]|\n",
      "|  9|        4.4|       2.9|        1.4|       0.2| setosa|[4.4,2.9,1.4,0.2]|\n",
      "| 10|        4.9|       3.1|        1.5|       0.1| setosa|[4.9,3.1,1.5,0.1]|\n",
      "| 11|        5.4|       3.7|        1.5|       0.2| setosa|[5.4,3.7,1.5,0.2]|\n",
      "| 12|        4.8|       3.4|        1.6|       0.2| setosa|[4.8,3.4,1.6,0.2]|\n",
      "| 13|        4.8|       3.0|        1.4|       0.1| setosa|[4.8,3.0,1.4,0.1]|\n",
      "| 14|        4.3|       3.0|        1.1|       0.1| setosa|[4.3,3.0,1.1,0.1]|\n",
      "| 15|        5.8|       4.0|        1.2|       0.2| setosa|[5.8,4.0,1.2,0.2]|\n",
      "| 16|        5.7|       4.4|        1.5|       0.4| setosa|[5.7,4.4,1.5,0.4]|\n",
      "| 17|        5.4|       3.9|        1.3|       0.4| setosa|[5.4,3.9,1.3,0.4]|\n",
      "| 18|        5.1|       3.5|        1.4|       0.3| setosa|[5.1,3.5,1.4,0.3]|\n",
      "| 19|        5.7|       3.8|        1.7|       0.3| setosa|[5.7,3.8,1.7,0.3]|\n",
      "| 20|        5.1|       3.8|        1.5|       0.3| setosa|[5.1,3.8,1.5,0.3]|\n",
      "+---+-----------+----------+-----------+----------+-------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_va.transform(iris_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rob_sc = RobustScaler(inputCol=num_va.getOutputCol(), outputCol='sca_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----------+-----------+----------+-------+-------------+\n",
      "| Id|SepalLength|SepalWidth|PetalLength|PetalWidth|Species|species_index|\n",
      "+---+-----------+----------+-----------+----------+-------+-------------+\n",
      "|  1|        5.1|       3.5|        1.4|       0.2| setosa|          0.0|\n",
      "|  2|        4.9|       3.0|        1.4|       0.2| setosa|          0.0|\n",
      "|  3|        4.7|       3.2|        1.3|       0.2| setosa|          0.0|\n",
      "|  4|        4.6|       3.1|        1.5|       0.2| setosa|          0.0|\n",
      "|  5|        5.0|       3.6|        1.4|       0.2| setosa|          0.0|\n",
      "|  6|        5.4|       3.9|        1.7|       0.4| setosa|          0.0|\n",
      "|  7|        4.6|       3.4|        1.4|       0.3| setosa|          0.0|\n",
      "|  8|        5.0|       3.4|        1.5|       0.2| setosa|          0.0|\n",
      "|  9|        4.4|       2.9|        1.4|       0.2| setosa|          0.0|\n",
      "| 10|        4.9|       3.1|        1.5|       0.1| setosa|          0.0|\n",
      "+---+-----------+----------+-----------+----------+-------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "str_indexer = StringIndexer(inputCol='Species', outputCol='species_index')\n",
    "str_indexer.fit(iris_df).transform(iris_df).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(inputCol= str_indexer.getOutputCol(), outputCol=\"ohe_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting it all together \n",
    "num_cat_va = VectorAssembler(inputCols=[\n",
    "    num_va.getOutputCol() # robust scaled numerical columns \n",
    "    ,ohe.getOutputCol() # encoded categorical columns\n",
    "],outputCol='final_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Pipeline(stages=[\n",
    "    num_va\n",
    "    ,rob_sc\n",
    "    ,str_indexer\n",
    "    ,ohe\n",
    "    ,num_cat_va])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_stage = p.getStages()[len(p.getStages()) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only the required columns for the ML algorithm \n",
    "input_features = p.fit(iris_df)\\\n",
    "                  .transform(iris_df)\\\n",
    "                  .select([last_stage.getOutputCol(), \"species_index\"]) #X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW PLUG INTO ML ALGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
