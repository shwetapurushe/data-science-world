{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*********************************IMP ENV VARIABLES IN ~bash_profile#*********************************\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# export PATH=\"/Users/spurushe/Documents/apache-maven-3.3.9/bin:$PATH\"\n",
    "# export SPARK_HOME=\"/Users/spurushe/spark/spark-2.3.1-bin-hadoop2.7\"\n",
    "\n",
    "# # FOR Pyspark\n",
    "# export PYSPARK_PYTHON=\"/Users/spurushe/spark/spark-2.3.1-bin-hadoop2.7/python\" #causes permission error 13 issues\n",
    "\n",
    "#USE THIS \n",
    "#export PYSPARK_PYTHON=\"/Library/Frameworks/Python.framework/Versions/3.6/bin/python3\"\n",
    "\n",
    "\n",
    "# #JAVA home\n",
    "# JAVA_HOME=$(/usr/libexec/java_home)\n",
    "# export JAVA_HOME;\n",
    "# #For R\n",
    "# export LD_LIBRARY_PATH=$JAVA_HOME/jre/lib/server;\n",
    "\n",
    "\n",
    "\n",
    "# # Setting PATH for Python 3.6\n",
    "# # The original version is saved in .bash_profile.pysave\n",
    "# PATH=\"/Library/Frameworks/Python.framework/Versions/3.6/bin:${PATH}\"\n",
    "# export PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark;\n",
    "#get_ipython().profile_dir.startup_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages net.snowflake:snowflake-jdbc:3.6.24,net.snowflake:spark-snowflake_2.11:2.4.12-spark_2.3 pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkConf, SparkContext \n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# sc_conf = SparkConf()\n",
    "# sc_conf.setAppName('Subscription_Predictor')\n",
    "# sc_conf.setMaster(\"local[*]\")\n",
    "# sc_conf.set('spark.driver.memory', '5G')\n",
    "# sc_conf.set('spark.executor.memory', '16G')\n",
    "# sc_conf.set('spark.memory.fraction', '0.6')\n",
    "# sc_conf.set('spark.executor.cores', '4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local').appName('test').config('spark.driver.memory', '5G').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession.Builder at 0x1079a96a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.builder.config('spark.executor.memory', '16G')\n",
    "spark.builder.config(\"spark.executor.cores\", \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNOWFLAKE_SOURCE_NAME = \"net.snowflake.spark.snowflake\"\n",
    "sfOptions = {\"sfURL\":\"*\", \"sfAccount\":\"*\", \"sfUser\":\"*\", \"sfPassword\":\"*\", \"sfDatabase\":\"*\", \"sfSchema\":\"*\", \"sfWarehouse\":\"*\"}\n",
    "df = spark.read.format(SNOWFLAKE_SOURCE_NAME).options(**sfOptions).option(\"*\", \"*\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "727165"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.20.20.20:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1084b84a8>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
