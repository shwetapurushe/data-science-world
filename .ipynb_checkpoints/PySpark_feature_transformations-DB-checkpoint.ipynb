{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark;\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import *\n",
    "\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkConf, SparkContext \n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.linalg import DenseVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession.Builder at 0x107ba7eb8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder.master('local').appName('playground').config('spark.driver.memory', '5G').getOrCreate()\n",
    "spark.builder.config('spark.executor.memory', '16G')\n",
    "spark.builder.config(\"spark.executor.cores\", \"4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Data \n",
    "df = spark.read.csv('iris_train.csv', header='true', inferSchema='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+----------+-----------+----------+-----------+------+----------+\n",
      "|Row_id|SepalLength|SepalWidth|PetalLength|PetalWidth|      Class|Smelly|    Status|\n",
      "+------+-----------+----------+-----------+----------+-----------+------+----------+\n",
      "|     1|        5.1|       3.5|        1.4|       0.2|Iris-setosa|   Yes|Developing|\n",
      "|     2|        4.9|       3.0|        1.4|       0.2|Iris-setosa|   Yes|Developing|\n",
      "|     3|        5.0|       3.6|        1.4|       0.2|Iris-setosa|   Yes|Developing|\n",
      "|     4|        4.8|       3.0|        1.4|       0.1|Iris-setosa|   Yes|Developing|\n",
      "|     5|        4.3|       3.0|        1.1|       0.1|Iris-setosa|   Yes|Developing|\n",
      "+------+-----------+----------+-----------+----------+-----------+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. String Indexing the Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Lets encode the Class column\n",
    "# target_st_indexer = StringIndexer(inputCol='Class', outputCol='indexed_class_column')\n",
    "# #You can chooose the way you want the String categories indexed.\n",
    "\n",
    "# target_st_indexer_model = target_st_indexer.fit(df)\n",
    "# transformed_df = target_st_indexer_model.transform(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that each category in the 'Class' column now is indexed with a separate number index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_st_indexer_model.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. String Indexing multiple predictor categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluding the target column\n",
    "# features = [item[0] for item in df.dtypes if item[1] =='string' and item[0] != 'Class']\n",
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexers for each of the categorical columns\n",
    "# st_indexers = list(map(lambda name: StringIndexer(inputCol=name, outputCol=\"indexed_\"+name)\n",
    "#                                , features))\n",
    "\n",
    "# pipeline = Pipeline(stages=st_indexers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two individual indexers for each categorical (predictor) columns, remember Class is the target column \n",
    "# st_indexers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexer_model = pipeline.fit(df)\n",
    "# transformed_df = indexer_model.transform(df)\n",
    "\n",
    "#To see what the results might look like\n",
    "#transformed_df.show(10)\n",
    "\n",
    "#String Indexing completed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Vector Assembler\n",
    "\n",
    "This transformer helps in collecting all the raw features and massaged categorical (encoded/indexed) features into a single feature vector.  \n",
    "Vector Assembler HAS to come AFTER an Indexer (StringIndexer etc) if your data has categorical predictor columns\n",
    "  \n",
    "A Vector Assembler cannot take categorical features for assembling.\n",
    "For eg. it cannot do [0.1, 76, 98, 'Yes', 'Red', 1]  \n",
    "It accepts boolean, numerical and vector types only, not StringType."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting the numerical (raw and massaged) input features \n",
    "#Row id does not provide any information \n",
    "# vecAss_features = [item[0] for item in transformed_df.dtypes if item[1] != 'string' and item[0] != 'Row_id' ]\n",
    "# vecAss_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec_assembler = VectorAssembler(inputCols=vecAss_features, outputCol=\"assembled_features\")\n",
    "\n",
    "\n",
    "# #How the assembler works by itself \n",
    "# assembled_pipeline = Pipeline(stages=[vec_assembler])\n",
    "# assembled_pipeline_model = assembled_pipeline.fit(transformed_df)\n",
    "\n",
    "# asb_transformed_df = assembled_pipeline_model.transform(transformed_df)\n",
    "# asb_transformed_df.select(\"assembled_features\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that all the numerical data has been assembled into vectors (one vector per record)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Vector Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vec_indexer = VectorIndexer(inputCol=\"assembled_features\", outputCol=\"indexed_ml_features\", maxCategories=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Transformation pipeline (this should create the input features space that goes into your ml algo)\n",
    "# i.e. your ML algo should use \"indexed_ml_features\" as its inputColumn\n",
    "\n",
    "# trans_pipeline = Pipeline(stages=[vec_assembler, vec_indexer])\n",
    "# trans_pipeline_model = trans_pipeline.fit(transformed_df)\n",
    "\n",
    "# ml_input_features_df = trans_pipeline_model.transform(transformed_df)\n",
    "# ml_input_features_df.select(\"indexed_ml_features\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dec_t = DecisionTreeClassifier(labelCol=\"indexed_class_column\", featuresCol=\"indexed_ml_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth', 'indexed_Smelly', 'indexed_Status']\n"
     ]
    }
   ],
   "source": [
    "# 1. Lets encode the categorical target column\n",
    "target_st_indexer = StringIndexer(inputCol='Class', outputCol='indexed_class_column')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. String Indexing the categorical predictor columns \n",
    "features = [item[0] for item in df.dtypes if item[1] =='string' and item[0] != 'Class']\n",
    "#print(\"Categorical pre\")\n",
    "st_indexers = list(map(lambda name: StringIndexer(inputCol=name, outputCol=\"indexed_\"+name)\n",
    "                               , features))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 3. Vector Assembler (create feature vector)\n",
    "vecAss_features = [item[0] for item in df.dtypes if item[1] != 'string' and item[0] != 'Row_id' ] +\\\n",
    "            ['indexed_Smelly', 'indexed_Status']\n",
    "#print(vecAss_features)\n",
    "vec_assembler = VectorAssembler(inputCols=vecAss_features, outputCol=\"assembled_features\")\n",
    "\n",
    "\n",
    "\n",
    "# 4. Vector Indexer\n",
    "vec_indexer = VectorIndexer(inputCol=\"assembled_features\", outputCol=\"indexed_ml_features\", maxCategories=2)\n",
    "\n",
    "\n",
    "\n",
    "# 5. ML algorithm Decision Tree here \n",
    "dec_t = DecisionTreeClassifier(labelCol=\"indexed_class_column\", featuresCol=\"indexed_ml_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_418ea0303ccf89b2aaa7,\n",
       " StringIndexer_4139970c7e63b1eb8d0a,\n",
       " StringIndexer_4396a20ffa517aa285f2,\n",
       " VectorAssembler_48c89eed70c494913edf,\n",
       " VectorIndexer_4e559fc1cfc1745c636c]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformation Pipeline\n",
    "\n",
    "trans_pipeline = Pipeline(stages=[target_st_indexer] + st_indexers +[ vec_assembler, vec_indexer])\n",
    "trans_pipeline.getStages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some concerns I have which I need advice for \n",
    "1. StringIndexer should be followed by a OneHotEncoder or a VectorIndexer to eliminate the order of indices.Using the string indexerâ€™s output directly as a feature will not make sense simply because if apples is indexed as 1 and orange as 2, this might be inferred as apples are at a higher rank than orange or orange is greater than an apple. Which is not the case \n",
    "\n",
    "2. One hot encoding (OHE) explodes every categorical column into n different features, n being the number of categories in that one categorical column So for eg. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weather</th>\n",
       "      <th>Weather_Hot</th>\n",
       "      <th>Weather_Cold</th>\n",
       "      <th>Weather_Humid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hot</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cold</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Humid</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Weather  Weather_Hot  Weather_Cold  Weather_Humid\n",
       "0     Hot            1             0              0\n",
       "1    Cold            0             1              0\n",
       "2   Humid            0             0              1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "d = {'Weather': ['Hot', 'Cold', \"Humid\"], 'Weather_Hot': [1,0,0], 'Weather_Cold': [0,1,0], 'Weather_Humid': [0,0,1]}\n",
    "df = pd.DataFrame(data=d)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With many different categorical columns this will explode the number of features a.k.a Curse of dimensionality. \n",
    "Ive prevented this using a VectorIndexer which does this in the background using maxCategories = 2.  \n",
    "**Does VectorIndexer this address the concern raised in #1 ?** \n",
    "\n",
    "3. The test/train split should be done on the transformed data.  \n",
    "**Is this correct?**    \n",
    "  \n",
    "**Does the above 'trans_pipeline' pipeline correct to you?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running all transformations BEFORE the train/test split\n",
    "transformed_df = trans_pipeline.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# TEST TRAIN SPLIT\n",
    "#\n",
    "#\n",
    "(trainData, testData) = transformed_df.randomSplit([0.8, 0.2], seed=2018)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# TRAINING THE DECISION TREE MODEL\n",
    "#\n",
    "#\n",
    "dec_t_model = dec_t.fit(trainData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Predictions\n",
    "#\n",
    "#\n",
    "\n",
    "predictions = dec_t_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our DT model in predicting flowers is  0.9047619047619048\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#\n",
    "#\n",
    "# MODEL EVALUATION\n",
    "#\n",
    "#\n",
    "eva = MulticlassClassificationEvaluator(labelCol='indexed_class_column',\\\n",
    "                                        predictionCol='prediction',\\\n",
    "                                        metricName='accuracy')\n",
    "\n",
    "print(\"Accuracy of our DT model in predicting flowers is \", eva.evaluate(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
