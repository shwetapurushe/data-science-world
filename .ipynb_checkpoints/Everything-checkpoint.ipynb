{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal\n",
    "\n",
    "To group customers into meaningful groups using \n",
    "1. Kmean clustering\n",
    "    * 1a.  All event data \n",
    "    * 1b. RFI clustering \n",
    "2. RFM analysis\n",
    "    * Analysis of RFI clustering, RFM manual buckets using quantiles and business knowledge\n",
    "3. Cohort analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark;\n",
    "#get_ipython().profile_dir.startup_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PYTHON MODULES\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime as dt\n",
    "import functools\n",
    "from pyspark.sql import functions as f\n",
    "from pandas.plotting import parallel_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark import SparkConf, SparkContext "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master('local').appName('test').config('spark.driver.memory', '5G').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession.Builder at 0x1117af208>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.builder.config('spark.executor.memory', '16G')\n",
    "spark.builder.config(\"spark.executor.cores\", \"4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm_df = spark.read.csv(\"/Users/spurushe/Documents/data-science-world/input_data/Online_Retail.csv\"\n",
    "                        , inferSchema=True\n",
    "                        ,header=True\n",
    "                        ,timestampFormat = \"MM/dd/yyyy hh:mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   536365|   85123A|WHITE HANGING HEA...|       6|0010-12-01 08:26:00|     2.55|     17850|United Kingdom|\n",
      "|   536365|    71053| WHITE METAL LANTERN|       6|0010-12-01 08:26:00|     3.39|     17850|United Kingdom|\n",
      "|   536365|   84406B|CREAM CUPID HEART...|       8|0010-12-01 08:26:00|     2.75|     17850|United Kingdom|\n",
      "|   536365|   84029G|KNITTED UNION FLA...|       6|0010-12-01 08:26:00|     3.39|     17850|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfm_df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: timestamp (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfm_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency Frequency Monetary Value metrics\n",
    "We will be treating this data as if it were recent and calculating a hypothetical 'today'.  \n",
    "Using this 'hypothetical today' lets calculate the RFM for the last 12 months. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics used \n",
    "* Recency -- time unit since last transaction (the lower the better) \n",
    "* Frequency -- number of transactions in the last (unit of time) (the higher the better)\n",
    "* Monetary Value -- total spend by the customer in the (unit of time) (the higher the better)\n",
    "\n",
    "Unit of time is chosen according to the (1) business model and the (2) product and customer lifecycle.\n",
    "\n",
    "Followed by Segmentation of RFM values which can be done by \n",
    "1. Percentiles or quantiles \n",
    "2. Pareto split i.e. 80/20 rule \n",
    "3. Based on predefined thresholds decided through business knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(A) Data should be very recent i.e. either today or yesterday. Else we need to create a hypothetical 'today' mimicking a recent snapshot of the data.  \n",
    "We will use this hypothetical today to calculate the recency.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the min and max transaction dates for the invoice\n",
    "#snapshot_date = rfm_df.select(['InvoiceDate']).groupby().agg({'InvoiceDate':'max'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "snapshot_date = f.max(rfm_df.InvoiceDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column<b'max(InvoiceDate)'>\n"
     ]
    }
   ],
   "source": [
    "snapshot_date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Segmentation using KMeans clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumptions of Kmeans clustering\n",
    "1. The data should be symmetrical -- check for skewness\n",
    "2. Same variance of each variable \n",
    "3. Same mean of each variable so that all variables contribute equally to the clustering. \n",
    "\n",
    "Therefore the pipeline should be \n",
    "1. Check for Skewness -- fix with log transformation\n",
    "2. Check for centrality -- fix with z score normalization (subtract by mean and divide by std)\n",
    "3. Kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
